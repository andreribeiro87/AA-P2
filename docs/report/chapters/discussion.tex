\section{Discussion}
\label{sec:discussion}

This section analyzes our experimental findings, comparing theoretical
predictions with practical observations, and identifying trade-offs and failure
modes of each algorithm category.

\subsection{Theoretical vs. Practical Complexity}
\label{sec:theory-vs-practice}

\subsubsection{Randomized Algorithms}

The theoretical $O(Tn^2)$ complexity of randomized algorithms matches our
observations: execution time grows quadratically with graph size and linearly
with the iteration count. However, practical performance varies significantly:

\begin{itemize}
    \item \textbf{Random Construction} performs better than expected because clique construction terminates early when no compatible vertices remain, reducing the effective complexity.
    \item \textbf{Monte Carlo} exhibits similar scaling but with higher constant factors due to probability computations.
    \item \textbf{Las Vegas} shows variable runtime as expected, with worst-case behavior on dense graphs where many random attempts fail to improve.
    \item \textbf{Iterative Random Search} suffers from the low probability of randomly generating large cliques, explaining its poor quality results.
\end{itemize}

\subsubsection{Exact Algorithms}

While theoretically exponential, the exact algorithms show much better
practical behavior:

\begin{itemize}
    \item \textbf{WLMC and TSM-MWC} benefit enormously from preprocessing, often reducing graph size by 50-80\% before search begins.
    \item Upper bound pruning eliminates most of the search space, making the algorithms
          practical for graphs up to $n=100$.
    \item Density has a pronounced effect: sparse graphs (12.5\%) are solved orders of
          magnitude faster than dense graphs (75\%).
\end{itemize}

\subsubsection{Reduction-Based Algorithms}

\begin{itemize}
    \item \textbf{MWCRedu's} $O(n^3)$ preprocessing dominates for small graphs but pays off for larger instances.
    \item The effectiveness of reduction rules depends heavily on graph
          structure---random graphs with uniform weights offer fewer reduction
          opportunities.
\end{itemize}

\subsection{Accuracy vs. Speed Trade-offs}
\label{sec:tradeoffs}

Our results reveal distinct trade-off profiles:

\begin{table}[H]
    \centering
    \caption{Algorithm Trade-off Summary}
    \label{tab:tradeoffs}
    \begin{tabular}{lccc}
        \toprule
        \textbf{Algorithm}   & \textbf{Speed} & \textbf{Quality} & \textbf{Recommended Use}    \\
        \midrule
        random\_construction & Fast           & High             & General purpose             \\
        monte\_carlo         & Medium         & High             & Probabilistic bounds        \\
        las\_vegas           & Variable       & Medium           & Correctness critical        \\
        mwc\_redu            & Very Fast      & Medium           & Large graphs, quick answer  \\
        max\_clique\_weight  & Slow           & Optimal          & Medium graphs, exact needed \\
        wlmc                 & Medium         & Optimal          & Large sparse graphs         \\
        fast\_wclq           & Fast           & Very High        & Production systems          \\
        scc\_walk            & Slow           & High             & Local refinement            \\
        \bottomrule
    \end{tabular}
\end{table}

\subsection{Best Use Cases}
\label{sec:use-cases}

Based on our analysis, we recommend:

\subsubsection{For Optimal Solutions}
\begin{itemize}
    \item \textbf{Small graphs ($n < 20$):} Any exact algorithm works; \texttt{exhaustive} for simplicity.
    \item \textbf{Medium graphs ($20 \leq n < 50$):} \texttt{wlmc} or \texttt{tsm\_mwc} with reasonable time limits.
    \item \textbf{Large sparse graphs:} \texttt{wlmc} with preprocessing excels.
    \item \textbf{Large dense graphs:} Consider \texttt{max\_clique\_dyn\_weight} for tighter bounds.
\end{itemize}

\subsubsection{For Fast Approximate Solutions}
\begin{itemize}
    \item \textbf{General use:} \texttt{random\_construction} offers surprising quality with speed.
    \item \textbf{Quality-critical:} \texttt{fast\_wclq} balances speed with near-optimal results.
    \item \textbf{Iterative refinement:} Start with \texttt{greedy}, refine with \texttt{scc\_walk}.
\end{itemize}

\subsubsection{For Real-time Applications}
\begin{itemize}
    \item \texttt{mwc\_redu} with greedy solver provides fastest results.
    \item Single-start greedy for microsecond latency requirements.
\end{itemize}

\subsection{Failure Points and Limitations}
\label{sec:failures}

\subsubsection{Algorithm-Specific Failures}

\begin{itemize}
    \item \textbf{Iterative Random Search:} Fundamentally flawed for MWC---the probability of randomly sampling a maximum clique decreases exponentially with clique size. Our implementation found essentially no valid solutions.

    \item \textbf{MWCPeel:} Aggressive peeling removes vertices that may be crucial for optimal cliques. Average quality of 79\% with some instances as low as 5.56\% indicates severe failure modes.

    \item \textbf{Las Vegas:} While guaranteeing correctness, it can get stuck in local optima. The 50.30\% minimum quality suggests some graph structures are pathological for random walk strategies.

    \item \textbf{MWCRedu:} Graph reduction effectiveness varies. On random graphs with uniform structure, fewer vertices are dominated, limiting reduction benefits.
\end{itemize}

\subsubsection{Density-Related Failures}

Higher density consistently degrades performance across all algorithms:
\begin{itemize}
    \item \textbf{Exact algorithms:} Exponentially more configurations to explore.
    \item \textbf{Randomized:} More compatible vertices at each step increases construction cost.
    \item \textbf{Local search:} Larger neighborhoods slow down move evaluation.
\end{itemize}

\subsubsection{Size-Related Failures}

\begin{itemize}
    \item \textbf{Exhaustive:} Becomes impractical beyond $n \approx 22$ due to $2^n$ configurations.
    \item \textbf{Branch-and-bound:} Without time limits, can still take exponential time on adversarial instances.
\end{itemize}

\subsection{Surprising Results}
\label{sec:surprises}

Several results were unexpected:

\begin{enumerate}
    \item \textbf{Random Construction achieving 100\% optimality} on test cases suggests that simple random construction with multiple restarts is highly effective for MWC, likely because the greedy extension phase tends to find maximal cliques of competitive weight.

    \item \textbf{Quality scores exceeding 100\%} (max 106.89\%) indicate discrepancies in weight calculations or floating-point precision issues between algorithms.

    \item \textbf{SCCWalk underperforming FastWClq} despite being a more sophisticated local search. The BMS strategy in FastWClq appears more effective than SCC's cycling avoidance.
\end{enumerate}

\subsection{Recommendations for Practitioners}
\label{sec:recommendations}

\begin{enumerate}
    \item \textbf{Default choice:} Use \texttt{fast\_wclq} for most applications---it combines speed with reliability.

    \item \textbf{When optimality matters:} Use \texttt{wlmc} with appropriate time limits.

    \item \textbf{For very large graphs:} Apply \texttt{mwc\_redu} preprocessing, then use \texttt{fast\_wclq} on the reduced graph.

    \item \textbf{Avoid:} \texttt{iterative\_random\_search} (poor quality) and \texttt{mwc\_peel} (unpredictable quality loss).

    \item \textbf{Benchmark first:} Algorithm performance varies with graph structure. Test on representative instances before deploying.
\end{enumerate}
